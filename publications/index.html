<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Publications | Liangming Pan </title> <meta name="author" content="Liangming Pan"> <meta name="description" content="* denotes equal contribution"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/avatar2.jpg?979379eb3bb27557e1ff6d4589365033"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://teacherpeterpan.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Liangming Pan </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Home </a> </li> <li class="nav-item "> <a class="nav-link" href="/bio/">Bio </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications / Preprints</h1> <p class="post-description">* denotes equal contribution</p> </header> <article> <p>Please see my <a href="https://scholar.google.com/citations?user=JcjjOTUAAAAJ" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i> Google Scholar</a> or <a href="https://semanticscholar.org/author/Liangming-Pan/3470231" target="_blank" rel="noopener noreferrer"><i class="ai ai-semantic-scholar"></i> Semantic Scholar</a> for the most up-to-date list of publications. </p> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">Preprints</h2> <h3 class="bibliography">2024</h3> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">arXiv</a> </abbr> </div> <div id="ma2024mmlongbenchdocbenchmarkinglongcontextdocument" class="col-sm-10"> <div class="title">MMLongBench-Doc: Benchmarking Long-context Document Understanding with Visualizations</div> <div class="author"> Yubo Ma, Yuhang Zang, Liangyu Chen, Meiqi Chen, Yizhu Jiao, Xinze Li, Xinyuan Lu, Ziyu Liu, Yan Ma, Xiaoyi Dong, Pan Zhang,  <a style="color: #0076df; font-weight: bold;">Liangming Pan</a>, Yu-Gang Jiang, Jiaqi Wang, Yixin Cao, and Aixin Sun </div> <div class="periodical"> <em>arXiv preprint</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract badge grey font-weight-light waves-effect mr-1" role="button">Abstract</a> <a class="bibtex badge grey font-weight-light waves-effect mr-1" role="button">Bib</a> <a href="https://arxiv.org/abs/2407.01523" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/mayubo2333/MMLongBench-Doc" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://huggingface.co/datasets/yubo2333/MMLongBench-Doc" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">Dataset</a> <a href="https://mayubo2333.github.io/MMLongBench-Doc/" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Understanding documents with rich layouts and multi-modal components is a long-standing and practical task. Recent Large Vision-Language Models (LVLMs) have made remarkable strides in various tasks, particularly in single-page document understanding (DU). However, their abilities on long-context DU remain an open problem. This work presents MMLongBench-Doc, a long-context, multi-modal benchmark comprising 1,062 expert-annotated questions. Distinct from previous datasets, it is constructed upon 130 lengthy PDF-formatted documents with an average of 49.4 pages and 20,971 textual tokens. Towards comprehensive evaluation, answers to these questions rely on pieces of evidence from (1) different sources (text, image, chart, table, and layout structure) and (2) various locations (i.e. page number). Moreover, 33.2% of the questions are cross-page questions requiring evidence across multiple pages. 22.8% of the questions are designed to be unanswerable for detecting potential hallucinations. Experiments on 14 LVLMs demonstrate that long-context DU greatly challenges current models. Notably, the best-performing model, GPT-4o, achieves an F1 score of only 42.7%, while the second-best, GPT-4V, scores 31.4%. Furthermore, 12 LVLMs (all except GPT-4o and GPT-4V) even present worse performance than their LLM counterparts which are fed with lossy-parsed OCR documents. These results validate the necessity of future research toward more capable long-context LVLMs.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">ma2024mmlongbenchdocbenchmarkinglongcontextdocument</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MMLongBench-Doc: Benchmarking Long-context Document Understanding with Visualizations}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ma, Yubo and Zang, Yuhang and Chen, Liangyu and Chen, Meiqi and Jiao, Yizhu and Li, Xinze and Lu, Xinyuan and Liu, Ziyu and Ma, Yan and Dong, Xiaoyi and Zhang, Pan and Pan, Liangming and Jiang, Yu-Gang and Wang, Jiaqi and Cao, Yixin and Sun, Aixin}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2407.01523}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.CV}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2407.01523}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">arXiv</a> </abbr> </div> <div id="yao2024seakrselfawareknowledgeretrieval" class="col-sm-10"> <div class="title">SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation</div> <div class="author"> Zijun Yao, Weijian Qi,  <a style="color: #0076df; font-weight: bold;">Liangming Pan</a>, Shulin Cao, Linmei Hu, Weichuan Liu, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Lei Hou, Juanzi Li' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>arXiv preprint</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract badge grey font-weight-light waves-effect mr-1" role="button">Abstract</a> <a class="bibtex badge grey font-weight-light waves-effect mr-1" role="button">Bib</a> <a href="https://arxiv.org/abs/2406.19215" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/thu-keg/seakr" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>This paper introduces Self-aware Knowledge Retrieval (SeaKR), a novel adaptive RAG model that extracts self-aware uncertainty of LLMs from their internal states. SeaKR activates retrieval when the LLMs present high self-aware uncertainty for generation. To effectively integrate retrieved knowledge snippets, SeaKR re-ranks them based on LLM’s self-aware uncertainty to preserve the snippet that reduces their uncertainty to the utmost. To facilitate solving complex tasks that require multiple retrievals, SeaKR utilizes their self-aware uncertainty to choose among different reasoning strategies. Our experiments on both complex and simple Question Answering datasets show that SeaKR outperforms existing adaptive RAG methods.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">yao2024seakrselfawareknowledgeretrieval</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yao, Zijun and Qi, Weijian and Pan, Liangming and Cao, Shulin and Hu, Linmei and Liu, Weichuan and Hou, Lei and Li, Juanzi}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2406.19215}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.CL}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2406.19215}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">arXiv</a> </abbr> </div> <div id="wong2024distilrrtransferringcoderepair" class="col-sm-10"> <div class="title">DistiLRR: Transferring Code Repair for Low-Resource Programming Languages</div> <div class="author"> Kyle Wong, Alfonso Amayuelas,  <a style="color: #0076df; font-weight: bold;">Liangming Pan</a>, and William Yang Wang </div> <div class="periodical"> <em>arXiv preprint</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract badge grey font-weight-light waves-effect mr-1" role="button">Abstract</a> <a class="bibtex badge grey font-weight-light waves-effect mr-1" role="button">Bib</a> <a href="https://arxiv.org/abs/2406.14867" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/kylewong288/distilrr" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Large language models (LLMs) have shown remarkable performance on code generation tasks. A recent application of LLMs for code generation is iterative code repair, where a model fixes an incorrect program by rationalizing about errors and generating a new program. However, code repair is primarily studied on high-resource languages like Python, and the framework’s efficacy is under-explored on low-resource languages. To apply code repair for low-resource languages, we propose Distilling Low-Resource Repairs (DistiLRR), an approach that transfers the reasoning and code generation ability from a teacher model to a student model. Our results show that DistiLRR consistently outperforms baselines on low-resource languages, but has similar performance on high-resource languages. To investigate this behavior, we perform a further analysis and find that the correlation between rationale quality and code correctness is weaker than previously perceived. We hypothesize this weakness is magnified in low-resource settings where base models lack deep knowledge of a programming language, leading to wavering benefits of code repair between high-resource and low-resource languages.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">wong2024distilrrtransferringcoderepair</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DistiLRR: Transferring Code Repair for Low-Resource Programming Languages}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wong, Kyle and Amayuelas, Alfonso and Pan, Liangming and Wang, William Yang}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2406.14867}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.LG}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2406.14867}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">arXiv</a> </abbr> </div> <div id="amayuelas2024multiagentcollaborationattackinvestigating" class="col-sm-10"> <div class="title">MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate</div> <div class="author"> Alfonso Amayuelas, Xianjun Yang, Antonis Antoniades, Wenyue Hua,  <a style="color: #0076df; font-weight: bold;">Liangming Pan</a>, and William Wang </div> <div class="periodical"> <em>arXiv preprint</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract badge grey font-weight-light waves-effect mr-1" role="button">Abstract</a> <a class="bibtex badge grey font-weight-light waves-effect mr-1" role="button">Bib</a> <a href="https://arxiv.org/abs/2406.14711" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Large Language Models (LLMs) have shown exceptional results on current benchmarks when working individually. The advancement in their capabilities, along with a reduction in parameter size and inference times, has facilitated the use of these models as agents, enabling interactions among multiple models to execute complex tasks. Such collaborations offer several advantages, including the use of specialized models (e.g. coding), improved confidence through multiple computations, and enhanced divergent thinking, leading to more diverse outputs. Thus, the collaborative use of language models is expected to grow significantly in the coming years. In this work, we evaluate the behavior of a network of models collaborating through debate under the influence of an adversary. We introduce pertinent metrics to assess the adversary’s effectiveness, focusing on system accuracy and model agreement. Our findings highlight the importance of a model’s persuasive ability in influencing others. Additionally, we explore inference-time methods to generate more compelling arguments and evaluate the potential of prompt-based mitigation as a defensive strategy.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">amayuelas2024multiagentcollaborationattackinvestigating</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Amayuelas, Alfonso and Yang, Xianjun and Antoniades, Antonis and Hua, Wenyue and Pan, Liangming and Wang, William}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2406.14711}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.CL}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2406.14711}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">arXiv</a> </abbr> </div> <div id="wu2024updatinglanguagemodelsunstructured" class="col-sm-10"> <div class="title">Updating Language Models with Unstructured Facts: Towards Practical Knowledge Editing</div> <div class="author"> Xiaobao Wu,  <a style="color: #0076df; font-weight: bold;">Liangming Pan</a>, William Yang Wang, and Anh Tuan Luu </div> <div class="periodical"> <em>arXiv preprint</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract badge grey font-weight-light waves-effect mr-1" role="button">Abstract</a> <a class="bibtex badge grey font-weight-light waves-effect mr-1" role="button">Bib</a> <a href="https://arxiv.org/abs/2402.18909" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Knowledge editing aims to inject knowledge updates into language models to keep them correct and up-to-date. However, its current evaluation strategies are notably impractical: they solely update with well-curated structured facts (triplets with subjects, relations, and objects), whereas real-world knowledge updates commonly emerge in unstructured texts like news articles. In this paper, we propose a new benchmark, Unstructured Knowledge Editing (UKE). It evaluates editing performance directly using unstructured texts as knowledge updates, termed unstructured facts. Hence UKE avoids the laborious construction of structured facts and enables efficient and responsive knowledge editing, becoming a more practical benchmark. We conduct extensive experiments on newly built datasets and demonstrate that UKE poses a significant challenge to state-of-the-art knowledge editing methods, resulting in their critical performance declines. We further show that this challenge persists even if we extract triplets as structured facts. Our analysis discloses key insights to motivate future research in UKE for more practical knowledge editing.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">wu2024updatinglanguagemodelsunstructured</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Updating Language Models with Unstructured Facts: Towards Practical Knowledge Editing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu, Xiaobao and Pan, Liangming and Wang, William Yang and Luu, Anh Tuan}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2402.18909}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.CL}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2402.18909}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">arXiv</a> </abbr> </div> <div id="ma2024sciagenttoolaugmentedlanguagemodels" class="col-sm-10"> <div class="title">SciAgent: Tool-augmented Language Models for Scientific Reasoning</div> <div class="author"> Yubo Ma, Zhibin Gou, Junheng Hao, Ruochen Xu, Shuohang Wang,  <a style="color: #0076df; font-weight: bold;">Liangming Pan</a>, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Yujiu Yang, Yixin Cao, Aixin Sun, Hany Awadalla, Weizhu Chen' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>arXiv preprint</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract badge grey font-weight-light waves-effect mr-1" role="button">Abstract</a> <a class="bibtex badge grey font-weight-light waves-effect mr-1" role="button">Bib</a> <a href="https://arxiv.org/abs/2402.11451" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Scientific reasoning poses an excessive challenge for even the most advanced Large Language Models (LLMs). To make this task more practical and solvable for LLMs, we introduce a new task setting named tool-augmented scientific reasoning. This setting supplements LLMs with scalable toolsets, and shifts the focus from pursuing an omniscient problem solver to a proficient tool-user. To facilitate the research of such setting, we construct a tool-augmented training corpus named MathFunc which encompasses over 30,000 samples and roughly 6,000 tools. Building on MathFunc, we develop SciAgent to retrieve, understand and, if necessary, use tools for scientific problem solving. Additionally, we craft a benchmark, SciToolBench, spanning five scientific domains to evaluate LLMs’ abilities with tool assistance. Extensive experiments on SciToolBench confirm the effectiveness of SciAgent. Notably, SciAgent-Mistral-7B surpasses other LLMs with the same size by more than 13% in absolute accuracy. Furthermore, SciAgent-DeepMath-7B shows much superior performance than ChatGPT.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">ma2024sciagenttoolaugmentedlanguagemodels</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SciAgent: Tool-augmented Language Models for Scientific Reasoning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ma, Yubo and Gou, Zhibin and Hao, Junheng and Xu, Ruochen and Wang, Shuohang and Pan, Liangming and Yang, Yujiu and Cao, Yixin and Sun, Aixin and Awadalla, Hany and Chen, Weizhu}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2402.11451}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.CL}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2402.11451}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">Conference &amp; Journal Papers</h2> <h3 class="bibliography">2024</h3> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">TACL</a> </abbr> </div> <div id="pan-etal-2024-automatically" class="col-sm-10"> <div class="title">Automatically Correcting Large Language Models: Surveying the Landscape of Diverse Automated Correction Strategies</div> <div class="author"> <a style="color: #0076df; font-weight: bold;">Liangming Pan</a>, Michael Saxon, Wenda Xu, Deepak Nathani, Xinyi Wang, and William Yang Wang </div> <div class="periodical"> <em>Transactions of the Association for Computational Linguistics (TACL)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract badge grey font-weight-light waves-effect mr-1" role="button">Abstract</a> <a class="bibtex badge grey font-weight-light waves-effect mr-1" role="button">Bib</a> <a href="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00660/120911" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/teacherpeterpan/self-correction-llm-papers" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">Website</a> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JcjjOTUAAAAJ&amp;citation_for_view=JcjjOTUAAAAJ:vV6vV6tmYwMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-110-4285F4?logo=googlescholar&amp;labelColor=beige" alt="110 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>While large language models (LLMs) have shown remarkable effectiveness in various NLP tasks, they are still prone to issues such as hallucination, unfaithful reasoning, and toxicity. A promising approach to rectify these flaws is correcting LLMs with feedback, where the LLM itself is prompted or guided with feedback to fix problems in its own output. Techniques leveraging automated feedback—either produced by the LLM itself (self-correction) or some external system—are of particular interest as they make LLM-based solutions more practical and deployable with minimal human intervention. This paper provides an exhaustive review of the recent advances in correcting LLMs with automated feedback, categorizing them into training-time, generation-time, and post-hoc approaches. We also identify potential challenges and future directions in this emerging field.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">pan-etal-2024-automatically</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automatically Correcting Large Language Models: Surveying the Landscape of Diverse Automated Correction Strategies}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pan, Liangming and Saxon, Michael and Xu, Wenda and Nathani, Deepak and Wang, Xinyi and Wang, William Yang}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Transactions of the Association for Computational Linguistics (TACL)}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Cambridge, MA}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{MIT Press}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2024.tacl-1.27}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{484--506}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">ACL</a> </abbr> </div> <div id="xu-etal-2024-faithful" class="col-sm-10"> <div class="title">Faithful Logical Reasoning via Symbolic Chain-of-Thought</div> <div class="author"> Jundong Xu, Hao Fei,  <a style="color: #0076df; font-weight: bold;">Liangming Pan</a>, Qian Liu, Mong-Li Lee, and Wynne Hsu </div> <div class="periodical"> <em>In Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract badge grey font-weight-light waves-effect mr-1" role="button">Abstract</a> <a class="bibtex badge grey font-weight-light waves-effect mr-1" role="button">Bib</a> <a href="https://arxiv.org/abs/2405.18357" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/aiden0526/symbcot" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>While the recent Chain-of-Thought (CoT) technique enhances the reasoning ability of large language models (LLMs) with the theory of mind, it might still struggle in handling logical reasoning that relies much on symbolic expressions and rigid deducing rules. To strengthen the logical reasoning capability of LLMs, we propose a novel Symbolic Chain-of-Thought, namely SymbCoT, a fully LLM-based framework that integrates symbolic expressions and logic rules with CoT prompting. Technically, building upon an LLM, SymbCoT 1) first translates the natural language context into the symbolic format, and then 2) derives a step-by-step plan to solve the problem with symbolic logical rules, 3) followed by a verifier to check the translation and reasoning chain. Via thorough evaluations on 5 standard datasets with both First-Order Logic and Constraint Optimization symbolic expressions, SymbCoT shows striking improvements over the CoT method consistently, meanwhile refreshing the current state-of-the-art performances. We further demonstrate that our system advances in more faithful, flexible, and explainable logical reasoning. To our knowledge, this is the first to combine symbolic expressions and rules into CoT for logical reasoning with LLMs.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">xu-etal-2024-faithful</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Faithful Logical Reasoning via Symbolic Chain-of-Thought}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Jundong and Fei, Hao and Pan, Liangming and Liu, Qian and Lee, Mong{-}Li and Hsu, Wynne}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Annual Meeting of the Association for Computational Linguistics (ACL)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Thailand}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2405.18357}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">ACL</a> </abbr> <span class="award badge">Oral Presentation</span> </div> <div id="xu-etal-2024-pride" class="col-sm-10"> <div class="title">Pride and Prejudice: LLM Amplifies Self-Bias in Self-Refinement</div> <div class="author"> Wenda Xu, Guanglei Zhu, Xuandong Zhao,  <a style="color: #0076df; font-weight: bold;">Liangming Pan</a>, Lei Li, and William Yang Wang </div> <div class="periodical"> <em>In Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract badge grey font-weight-light waves-effect mr-1" role="button">Abstract</a> <a class="bibtex badge grey font-weight-light waves-effect mr-1" role="button">Bib</a> <a href="https://arxiv.org/abs/2402.11436" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/xu1998hz/llm_self_bias" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JcjjOTUAAAAJ&amp;citation_for_view=JcjjOTUAAAAJ:3s1wT3WcHBgC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-7-4285F4?logo=googlescholar&amp;labelColor=beige" alt="7 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Recent studies show that large language models (LLMs) improve their performance through self-feedback on certain tasks while degrade on others. We discovered that such a contrary is due to LLM’s bias in evaluating their own output. In this paper, we formally define LLM’s self-bias - the tendency to favor its own generation - using two statistics. We analyze six LLMs (GPT-4, GPT-3.5, Gemini, LLaMA2, Mixtral and DeepSeek) on translation, constrained text generation, and mathematical reasoning tasks. We find that self-bias is prevalent in all examined LLMs across multiple languages and tasks. Our analysis reveals that while the self-refine pipeline improves the fluency and understandability of model outputs, it further amplifies self-bias. To mitigate such biases, we discover that larger model size and external feedback with accurate assessment can significantly reduce bias in the self-refine pipeline, leading to actual performance improvement in downstream tasks.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">xu-etal-2024-pride</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Pride and Prejudice: LLM Amplifies Self-Bias in Self-Refinement}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Wenda and Zhu, Guanglei and Zhao, Xuandong and Pan, Liangming and Li, Lei and Wang, William Yang}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Annual Meeting of the Association for Computational Linguistics (ACL)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Thailand}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2402.11436}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">ACL</a> </abbr> </div> <div id="alfonso-etal-2024-knowledge" class="col-sm-10"> <div class="title">Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large Language Models</div> <div class="author"> Alfonso Amayuelas, Kyle Wong,  <a style="color: #0076df; font-weight: bold;">Liangming Pan</a>, Wenhu Chen, and William Yang Wang </div> <div class="periodical"> <em>In Findings of Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract badge grey font-weight-light waves-effect mr-1" role="button">Abstract</a> <a class="bibtex badge grey font-weight-light waves-effect mr-1" role="button">Bib</a> <a href="https://arxiv.org/abs/2305.13712" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/amayuelas/knowledge-of-knowledge" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JcjjOTUAAAAJ&amp;citation_for_view=JcjjOTUAAAAJ:TQgYirikUcIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-26-4285F4?logo=googlescholar&amp;labelColor=beige" alt="26 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>This paper investigates the capabilities of Large Language Models (LLMs) in the context of understanding their knowledge and uncertainty over questions. Specifically, we focus on addressing known-unknown questions, characterized by high uncertainty due to the absence of definitive answers. To facilitate our study, we collect a new dataset with Known-Unknown Questions (KUQ) and establish a categorization framework to clarify the origins of uncertainty in such queries. Subsequently, we examine the performance of open-source LLMs, fine-tuned using this dataset, in distinguishing between known and unknown queries within open-ended question-answering scenarios. The fine-tuned models demonstrated a significant improvement, achieving a considerable increase in F1-score relative to their pre-fine-tuning state. Through a comprehensive analysis, we reveal insights into the models’ improved uncertainty articulation and their consequent efficacy in multi-agent debates. These findings help us understand how LLMs can be trained to identify and express uncertainty, improving our knowledge of how they understand and express complex or unclear information.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">alfonso-etal-2024-knowledge</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Amayuelas, Alfonso and Wong, Kyle and Pan, Liangming and Chen, Wenhu and Wang, William Yang}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of Annual Meeting of the Association for Computational Linguistics (ACL)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Thailand}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2305.13712}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">ACL</a> </abbr> </div> <div id="zhang-etal-2024-knowledge" class="col-sm-10"> <div class="title">The Knowledge Alignment Problem: Bridging Human and External Knowledge for Large Language Models</div> <div class="author"> Shuo Zhang,  <a style="color: #0076df; font-weight: bold;">Liangming Pan</a>, Junzhou Zhao, and William Yang Wang </div> <div class="periodical"> <em>In Findings of Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract badge grey font-weight-light waves-effect mr-1" role="button">Abstract</a> <a class="bibtex badge grey font-weight-light waves-effect mr-1" role="button">Bib</a> <a href="https://arxiv.org/abs/2305.13669" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/shuozhangxjtu/mixalign" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JcjjOTUAAAAJ&amp;citation_for_view=JcjjOTUAAAAJ:M05iB0D1s5AC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-26-4285F4?logo=googlescholar&amp;labelColor=beige" alt="26 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Large language models often necessitate grounding on external knowledge to generate faithful and reliable answers. Yet even with the correct groundings in the reference, they can ignore them and rely on wrong groundings or their inherent biases to hallucinate when users, being largely unaware of the specifics of the stored information, pose questions that might not directly correlate with the retrieved groundings. In this work, we formulate this knowledge alignment problem and introduce MixAlign, a framework that interacts with both the human user and the knowledge base to obtain and integrate clarifications on how the user question relates to the stored information. MixAlign employs a language model to achieve automatic knowledge alignment and, if necessary, further enhances this alignment through human user clarifications. Experimental results highlight the crucial role of knowledge alignment in boosting model performance and mitigating hallucination, with improvements noted up to 22.2% and 27.1% respectively. We also demonstrate the effectiveness of MixAlign in improving knowledge alignment by producing high-quality, user-centered clarifications.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang-etal-2024-knowledge</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Knowledge Alignment Problem: Bridging Human and External Knowledge for Large Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Shuo and Pan, Liangming and Zhao, Junzhou and Wang, William Yang}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of Annual Meeting of the Association for Computational Linguistics (ACL)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Thailand}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2305.13669}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">ACL</a> </abbr> </div> <div id="li-etal-2024-towards" class="col-sm-10"> <div class="title">Towards Verifiable Generation: A Benchmark for Knowledge-aware Language Model Attribution</div> <div class="author"> Xinze Li, Yixin Cao,  <a style="color: #0076df; font-weight: bold;">Liangming Pan</a>, Yubo Ma, and Aixin Sun </div> <div class="periodical"> <em>In Findings of Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract badge grey font-weight-light waves-effect mr-1" role="button">Abstract</a> <a class="bibtex badge grey font-weight-light waves-effect mr-1" role="button">Bib</a> <a href="https://arxiv.org/abs/2310.05634" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Although achieving great success, Large Language Models (LLMs) usually suffer from unreliable hallucinations. Although language attribution can be a potential solution, there are no suitable benchmarks and evaluation metrics to attribute LLMs to structured knowledge. In this paper, we define a new task of Knowledge-aware Language Model Attribution (KaLMA) that improves upon three core concerns with conventional attributed LMs. First, we extend attribution source from unstructured texts to Knowledge Graph (KG), whose rich structures benefit both the attribution performance and working scenarios. Second, we propose a new “Conscious Incompetence” setting considering the incomplete knowledge repository, where the model identifies the need for supporting knowledge beyond the provided KG. Third, we propose a comprehensive automatic evaluation metric encompassing text quality, citation quality, and text citation alignment. To implement the above innovations, we build a dataset in biography domain BioKaLMA via evolutionary question generation strategy, to control the question complexity and necessary knowledge to the answer. For evaluation, we develop a baseline solution and demonstrate the room for improvement in LLMs’ citation generation, emphasizing the importance of incorporating the “Conscious Incompetence” setting, and the critical role of retrieval accuracy.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">li-etal-2024-towards</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Towards Verifiable Generation: A Benchmark for Knowledge-aware Language Model Attribution}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Xinze and Cao, Yixin and Pan, Liangming and Ma, Yubo and Sun, Aixin}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of Annual Meeting of the Association for Computational Linguistics (ACL)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Thailand}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2310.05634}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">ACL</a> </abbr> </div> <div id="wu-etal-2024-modeling" class="col-sm-10"> <div class="title">Modeling Dynamic Topics in Chain-Free Fashion by Evolution-Tracking Contrastive Learning and Unassociated Word Exclusion</div> <div class="author"> Xiaobao Wu, Xinshuai Dong,  <a style="color: #0076df; font-weight: bold;">Liangming Pan</a>, Thong Nguyen, and Anh Tuan Luu </div> <div class="periodical"> <em>In Findings of Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract badge grey font-weight-light waves-effect mr-1" role="button">Abstract</a> <a class="bibtex badge grey font-weight-light waves-effect mr-1" role="button">Bib</a> <a href="https://arxiv.org/abs/2405.17957" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/bobxwu/CFDTM" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Dynamic topic models track the evolution of topics in sequential documents, which have derived various applications like trend analysis and opinion mining. However, existing models suffer from repetitive topic and unassociated topic issues, failing to reveal the evolution and hindering further applications. To address these issues, we break the tradition of simply chaining topics in existing work and propose a novel neural \modelfullname. We introduce a new evolution-tracking contrastive learning method that builds the similarity relations among dynamic topics. This not only tracks topic evolution but also maintains topic diversity, mitigating the repetitive topic issue. To avoid unassociated topics, we further present an unassociated word exclusion method that consistently excludes unassociated words from discovered topics. Extensive experiments demonstrate our model significantly outperforms state-of-the-art baselines, tracking topic evolution with high-quality topics, showing better performance on downstream tasks, and remaining robust to the hyperparameter for evolution intensities.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wu-etal-2024-modeling</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Modeling Dynamic Topics in Chain-Free Fashion by Evolution-Tracking Contrastive Learning and Unassociated Word Exclusion}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu, Xiaobao and Dong, Xinshuai and Pan, Liangming and Nguyen, Thong and Luu, Anh Tuan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of Annual Meeting of the Association for Computational Linguistics (ACL)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Thailand}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2405.17957}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">ICML</a> </abbr> </div> <div id="wang-etal-2024-understanding" class="col-sm-10"> <div class="title">Understanding Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation</div> <div class="author"> Xinyi Wang, Alfonso Amayuelas, Kexun Zhang,  <a style="color: #0076df; font-weight: bold;">Liangming Pan</a>, Wenhu Chen, and William Yang Wang </div> <div class="periodical"> <em>In International Conference on Machine Learning (ICML)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract badge grey font-weight-light waves-effect mr-1" role="button">Abstract</a> <a class="bibtex badge grey font-weight-light waves-effect mr-1" role="button">Bib</a> <a href="https://arxiv.org/abs/2402.03268" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/wangxinyilinda/lm_random_walk" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Pre-trained language models (LMs) are able to perform complex reasoning without explicit fine-tuning. To understand how pre-training with a next-token prediction objective contributes to the emergence of such reasoning capability, we propose that we can view an LM as deriving new conclusions by aggregating indirect reasoning paths seen at pre-training time. We found this perspective effective in two important cases of reasoning: logic reasoning with knowledge graphs (KGs) and chain-of-thought (CoT) reasoning. More specifically, we formalize the reasoning paths as random walk paths on the knowledge/reasoning graphs. Analyses of learned LM distributions suggest that a weighted sum of relevant random walk path probabilities is a reasonable way to explain how LMs reason. Experiments and analysis on multiple KG and CoT datasets reveal the effect of training on random walk paths and suggest that augmenting unlabeled random walk reasoning paths can improve real-world multi-step reasoning performance.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wang-etal-2024-understanding</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Understanding Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Xinyi and Amayuelas, Alfonso and Zhang, Kexun and Pan, Liangming and Chen, Wenhu and Wang, William Yang}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Machine Learning (ICML)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Austria}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2402.03268}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">ICML</a> </abbr> </div> <div id="weissburg-etal-2024-tweets" class="col-sm-10"> <div class="title">Tweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility</div> <div class="author"> Iain Xie Weissburg, Mehir Arora, Xinyi Wang,  <a style="color: #0076df; font-weight: bold;">Liangming Pan</a>, and William Yang Wang </div> <div class="periodical"> <em>In International Conference on Machine Learning (ICML)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract badge grey font-weight-light waves-effect mr-1" role="button">Abstract</a> <a class="bibtex badge grey font-weight-light waves-effect mr-1" role="button">Bib</a> <a href="https://arxiv.org/abs/2401.13782" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>As the number of accepted papers at AI and ML conferences reaches into the thousands, it has become unclear how researchers access and read research publications. In this paper, we investigate the role of social media influencers in enhancing the visibility of machine learning research, particularly the citation counts of papers they share. We have compiled a comprehensive dataset of over 8,000 papers, spanning tweets from December 2018 to October 2023, alongside controls precisely matched by 9 key covariates. Our statistical and causal inference analysis reveals a significant increase in citations for papers endorsed by these influencers, with median citation counts 2-3 times higher than those of the control group. Additionally, the study delves into the geographic, gender, and institutional diversity of highlighted authors. Given these findings, we advocate for a responsible approach to curation, encouraging influencers to uphold the journalistic standard that includes showcasing diverse research topics, authors, and institutions.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">weissburg-etal-2024-tweets</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Tweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Weissburg, Iain Xie and Arora, Mehir and Wang, Xinyi and Pan, Liangming and Wang, William Yang}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Machine Learning (ICML)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Austria}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2401.13782}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h3 class="bibliography">2023</h3> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">EMNLP</a> </abbr> </div> <div id="pan-etal-2023-logic" class="col-sm-10"> <div class="title">Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning</div> <div class="author"> <a style="color: #0076df; font-weight: bold;">Liangming Pan</a>, Alon Albalak, Xinyi Wang, and William Wang </div> <div class="periodical"> <em>In Findings of Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract badge grey font-weight-light waves-effect mr-1" role="button">Abstract</a> <a class="bibtex badge grey font-weight-light waves-effect mr-1" role="button">Bib</a> <a href="https://arxiv.org/abs/2305.12295" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/teacherpeterpan/logic-llm" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JcjjOTUAAAAJ&amp;citation_for_view=JcjjOTUAAAAJ:RHpTSmoSYBkC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-84-4285F4?logo=googlescholar&amp;labelColor=beige" alt="84 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Large Language Models (LLMs) have shown human-like reasoning abilities but still struggle with complex logical problems. This paper introduces a novel framework, Logic-LM, which integrates LLMs with symbolic solvers to improve logical problem-solving. Our method first utilizes LLMs to translate a natural language problem into a symbolic formulation. Afterward, a deterministic symbolic solver performs inference on the formulated problem. We also introduce a self-refinement module, which utilizes the symbolic solver’s error messages to revise symbolic formalizations. We demonstrate Logic-LM’s effectiveness on five logical reasoning datasets: ProofWriter, PrOntoQA, FOLIO, LogicalDeduction, and AR-LSAT. On average, Logic-LM achieves a significant performance boost of 39.2% over using LLM alone with standard prompting and 18.4% over LLM with chain-of-thought prompting. Our findings suggest that Logic-LM, by combining LLMs with symbolic logic, offers a promising avenue for faithful logical reasoning.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">pan-etal-2023-logic</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Logic-{LM}: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pan, Liangming and Albalak, Alon and Wang, Xinyi and Wang, William}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of Conference on Empirical Methods in Natural Language Processing (EMNLP)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Singapore}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2023.findings-emnlp.248}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3806--3824}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">EMNLP</a> </abbr> </div> <div id="pan-etal-2023-risk" class="col-sm-10"> <div class="title">On the Risk of Misinformation Pollution with Large Language Models</div> <div class="author"> Yikang Pan<sup>*</sup>,  <a style="color: #0076df; font-weight: bold;">Liangming Pan<sup>*</sup></a>, Wenhu Chen, Preslav Nakov, Min-Yen Kan, and William Wang </div> <div class="periodical"> <em>In Findings of Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract badge grey font-weight-light waves-effect mr-1" role="button">Abstract</a> <a class="bibtex badge grey font-weight-light waves-effect mr-1" role="button">Bib</a> <a href="https://arxiv.org/abs/2305.13661" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/MexicanLemonade/LLM-Misinfo-QA" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JcjjOTUAAAAJ&amp;citation_for_view=JcjjOTUAAAAJ:mB3voiENLucC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-84-4285F4?logo=googlescholar&amp;labelColor=beige" alt="84 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>We investigate the potential misuse of modern Large Language Models (LLMs) for generating credible-sounding misinformation and its subsequent impact on information-intensive applications, particularly Open-Domain Question Answering (ODQA) systems. We establish a threat model and simulate potential misuse scenarios, both unintentional and intentional, to assess the extent to which LLMs can be utilized to produce misinformation. Our study reveals that LLMs can act as effective misinformation generators, leading to a significant degradation (up to 87%) in the performance of ODQA systems. Moreover, we uncover disparities in the attributes associated with persuading humans and machines, presenting an obstacle to current human-centric approaches to combat misinformation. To mitigate the harm caused by LLM-generated misinformation, we propose three defense strategies: misinformation detection, vigilant prompting, and reader ensemble. These approaches have demonstrated promising results, albeit with certain associated costs. Lastly, we discuss the practicality of utilizing LLMs as automatic misinformation generators and provide relevant resources and code to facilitate future research in this area.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">pan-etal-2023-risk</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On the Risk of Misinformation Pollution with Large Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pan, Yikang and Pan, Liangming and Chen, Wenhu and Nakov, Preslav and Kan, Min-Yen and Wang, William}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of Conference on Empirical Methods in Natural Language Processing (EMNLP)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Singapore}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2023.findings-emnlp.97}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1389--1403}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">EMNLP</a> </abbr> </div> <div id="lu-etal-2023-scitab" class="col-sm-10"> <div class="title">SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables</div> <div class="author"> Xinyuan Lu<sup>*</sup>,  <a style="color: #0076df; font-weight: bold;">Liangming Pan<sup>*</sup></a>, Qian Liu, Preslav Nakov, and Min-Yen Kan </div> <div class="periodical"> <em>In Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract badge grey font-weight-light waves-effect mr-1" role="button">Abstract</a> <a class="bibtex badge grey font-weight-light waves-effect mr-1" role="button">Bib</a> <a href="https://arxiv.org/abs/2305.13186" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/xinyuanlu00/scitab" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JcjjOTUAAAAJ&amp;citation_for_view=JcjjOTUAAAAJ:hFOr9nPyWt4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-8-4285F4?logo=googlescholar&amp;labelColor=beige" alt="8 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Current scientific fact-checking benchmarks exhibit several shortcomings, such as biases arising from crowd-sourced claims and an over-reliance on text-based evidence. We present SCITAB, a challenging evaluation dataset consisting of 1.2K expert-verified scientific claims that 1) originate from authentic scientific publications and 2) require compositional reasoning for verification. The claims are paired with evidence-containing scientific tables annotated with labels. Through extensive evaluations, we demonstrate that SCITAB poses a significant challenge to state-of-the-art models, including table-based pretraining models and large language models. All models except GPT-4 achieved performance barely above random guessing. Popular prompting techniques, such as Chain-of-Thought, do not achieve much performance gains on SCITAB. Our analysis uncovers several unique challenges posed by SCITAB, including table grounding, claim ambiguity, and compositional reasoning. Our codes and data are publicly available at https://github.com/XinyuanLu00/SciTab.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">lu-etal-2023-scitab</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{SCITAB}: A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lu, Xinyuan and Pan, Liangming and Liu, Qian and Nakov, Preslav and Kan, Min-Yen}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Conference on Empirical Methods in Natural Language Processing (EMNLP)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Singapore}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2023.emnlp-main.483}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{7787--7813}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">PhD thesis</h2> <h3 class="bibliography">2022</h3> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0076df"> <a href="">PhD thesis</a> </abbr> </div> <div id="phdthesis-pan-2022-QG" class="col-sm-10"> <div class="title">Towards Generating Deep Questions from Text</div> <div class="author"> <a style="color: #0076df; font-weight: bold;">Liangming Pan</a> </div> <div class="periodical"> <em>National University of Singapore</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://www.proquest.com/docview/2723857718?pq-origsite=gscholar&amp;fromopenview=true&amp;sourcetype=Dissertations%20&amp;%20Theses" class="badge grey font-weight-light waves-effect mr-1" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Liangming Pan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-home",title:"Home",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-bio",title:"Bio",description:"You can find a PDF version of my full CV on the right.",section:"Navigation",handler:()=>{window.location.href="/bio/"}},{id:"nav-publications",title:"Publications",description:"* denotes equal contribution",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-a-post-with-github-metadata",title:"a post with github metadata",description:"a quick run down on accessing github metadata.",section:"Posts",handler:()=>{window.location.href="/blog/2020/github-metadata/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march &amp; april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-from-september-to-december-i-joined-mohamed-bin-zayed-university-of-artificial-intelligence-mbzuai-as-a-short-term-research-fellow-working-with-prof-preslav-nakov",title:"From September to December, I joined Mohamed bin Zayed University of Artificial Intelligence...",description:"",section:"News"},{id:"news-i-will-serve-as-an-area-chair-for-the-question-answering-track-of-acl-2023-starting-from-dec-2022-i-am-thrilled-to-join-the-uc-santa-barbara-natural-language-processing-group-as-a-postdoctoral-scholar-working-with-prof-william-yang-wang",title:"I will serve as an Area Chair for the Question Answering track of...",description:"",section:"News"},{id:"news-our-paper-hashtag-guided-low-resource-tweet-classification-was-accepted-by-www-2023-invited-talk-building-data-efficient-and-explainable-fact-checking-models-at-mohamed-bin-zayed-university-of-artificial-intelligence-mbzuai",title:"Our paper Hashtag-Guided Low-Resource Tweet Classification was accepted by WWW 2023. Invited Talk...",description:"",section:"News"},{id:"news-new-preprint-logic-lm-empowering-large-language-models-with-symbolic-solvers-for-faithful-logical-reasoning-our-paper-fact-checking-complex-claims-with-program-guided-reasoning-was-accepted-by-the-main-conference-of-acl-2023",title:"New Preprint! Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical...",description:"",section:"News"},{id:"news-new-survey-paper-automatically-correcting-large-language-models-surveying-the-landscape-of-diverse-self-correction-strategies-we-also-create-a-paper-list",title:"New Survey Paper! Automatically Correcting Large Language Models: Surveying the landscape of diverse...",description:"",section:"News"},{id:"news-i-have-8-papers-accepted-by-emnlp-2023-4-main-conference-3-findings-1-demo-topics-involves-logical-reasoning-safety-and-evaluation-of-llms",title:"I have 8 papers accepted by EMNLP 2023 (4 Main Conference, 3 Findings,...",description:"",section:"News"},{id:"news-our-paper-attacking-open-domain-question-answering-by-injecting-misinformation-received-the-area-chair-award-question-answering-at-ijcnlp-aacl-2023",title:"Our paper Attacking Open-domain Question Answering by Injecting Misinformation received the Area Chair...",description:"",section:"News"},{id:"news-invited-talk-combating-misinformation-in-the-age-of-llms-at-nus-centre-for-trusted-internet-and-community-slides",title:"Invited talk \u201cCombating Misinformation in the age of LLMs\u201d at NUS Centre for...",description:"",section:"News"},{id:"news-i-will-serve-as-the-student-volunteer-chair-and-an-area-chair-of-acl-2024",title:"I will serve as the Student Volunteer Chair and an Area Chair of...",description:"",section:"News"},{id:"news-6-papers-accepted-by-acl-2024-2-main-conference-4-findings-topics-involves-logical-reasoning-uncertainty-estimation-and-self-correction-of-llms-2-papers-accepted-by-icml-2024-one-paper-is-on-understanding-the-chain-of-thought-reasoning-ability-of-llms-the-other-paper-is-on-analyzing-the-impact-of-social-media-influencers-on-ai-research-visibility",title:"6 papers accepted by ACL 2024 (2 Main Conference, 4 Findings). Topics involves...",description:"",section:"News"},{id:"news-invited-talk-empowering-large-language-models-with-faithful-reasoning-at-tsinghua-university-peking-university-xi-an-jiaotong-university-and-harbin-institute-of-technology-shenzhen",title:"Invited talk \u201cEmpowering Large Language Models with Faithful Reasoning\u201d at Tsinghua University, Peking...",description:"",section:"News"},{id:"news-i-will-serve-as-an-area-chair-for-emnlp-2024-and-coling-2025",title:"I will serve as an Area Chair for EMNLP 2024 and COLING 2025....",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6C%69%61%6E%67%6D%69%6E%67%70%61%6E@%75%63%73%62.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=JcjjOTUAAAAJ","_blank")}},{id:"socials-semantic-scholar",title:"Semantic Scholar",section:"Socials",handler:()=>{window.open("https://www.semanticscholar.org/author/Liangming-Pan/3470231","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/teacherpeterpan","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/liangmingpan/en","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/PanLiangming","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>